College
Boston
#setup
library(MASS) #used for Boston dataframe
library(gcdnet) #used for adaptive elastic net regression
library(tidyverse) #data cleaning and analysis
set.seed(23122) #set seed to keep consistent results
nrows <- nrow(Boston)
train <- sample(1:nrow(Boston),size=round(nrows*.75))  #seperate 75% into training data
######Separating data#####
train_x_data <-  as.matrix(Boston[train, 1:length(Boston)-1])  #training x data
train_y_data <- as.matrix(Boston[train, "medv"])  #training y data (AKA labels)
test_x_data <- as.matrix(Boston[-train, 1:length(Boston)-1])
test_y_data <- Boston[-train, "medv"]
Boston
adap_enet <- cv.gcdnet(x = train_x_data, y = train_y_data, nfolds = 10)
adap_enet <- cv.gcdnet(x = train_x_data, y = train_y_data, nfolds = 10, method = "ls")
View(adap_enet)
y_hat <- predict(adap_enet, test_x_data)
?predict.cv.gcdnet
y_hat <- predict(adap_enet, newx = test_x_data)
mse <- mean((y_hat - test_y_data)^2)
library(glmnet) #used for lasso regression
lasso <- cv.glmnet(x = train_x_data, y = train_y_data, alpha = 1)
lasso_yhat <- predict(lasso, newx = test_x_data)
lasso_mse <- mean((lasso_yhat - test_y_data)^2)
# R version: 4.1.0
library(tidyverse) # v1.3.1
library(dplyr) # v1.0.6
library(faux) # v1.0.0
library(ncvreg) # v3.13.0
library(glmnet) # v4.1-1
# Used for stepwise selection.
library(MASS) # v7.3-54
# Used for confusion matrices.
library(caret) # v6.0-88
# Used to set the current working directory to this script.
library(rstudioapi) # v0.13
library(bit64) # v4.0.5
# Used for XGBoost models.
library(xgboost) # v1.4.1.1
# Used for random forest models.
library(ranger) # v0.12.1
# Support vector machine model
library(e1071) # v1.7-7
setwd(dirname(getActiveDocumentContext()$path))
source("simulation.r")
source("metrics.r")
#random_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#models <- fit_models(dat = random_data, n = 100, p = 10)
#test_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#lasso_pred <- predict(models$lasso, as.matrix(test_data[, -1]))
#lasso_eval <- data.frame(lasso_pred, test_data[, 1])
#lasso_mse <- 1/100 * sum((lasso_eval[, 1] - lasso_eval[, 2])^2)
#rf_pred <- h2o.performance(models$rf, newdata = as.h2o(test_data))
#rf_pred <- as.data.frame(predict(object = models$rf, newdata = as.h2o(test_data[, -1])))
#rf_eval <- data.frame(rf_pred, test_data[, 1])
#rf_mse <- 1/100 * sum((rf_eval[, 1] - rf_eval[, 2])^2)
#rf_eval[3] <- lasso_eval[1]
#colnames(rf_eval) <- c("rf", "true", "lasso")
system.time(dat <- monte_carlo(n = 1000,
p = 100,
type = "symmetric",
corr = 0.5,
sd = 1,
iterations = 1,
seed = 1
))
# monte-carlo.r
# Gabe Ackall, Seongtae Kim, Connor Shrader
# This file contains everything to be executed using the functions from
# simulation.r and metrics.r.
# R version: 4.1.0
library(tidyverse) # v1.3.1
library(dplyr) # v1.0.6
library(faux) # v1.0.0
library(ncvreg) # v3.13.0
library(glmnet) # v4.1-1
# Used for stepwise selection.
library(MASS) # v7.3-54
# Used for confusion matrices.
library(caret) # v6.0-88
# Used to set the current working directory to this script.
library(rstudioapi) # v0.13
library(bit64) # v4.0.5
# Used for XGBoost models.
library(xgboost) # v1.4.1.1
# Used for random forest models.
library(ranger) # v0.12.1
# Support vector machine model
library(e1071) # v1.7-7
setwd(dirname(getActiveDocumentContext()$path))
source("simulation.r")
source("metrics.r")
#random_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#models <- fit_models(dat = random_data, n = 100, p = 10)
#test_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#lasso_pred <- predict(models$lasso, as.matrix(test_data[, -1]))
#lasso_eval <- data.frame(lasso_pred, test_data[, 1])
#lasso_mse <- 1/100 * sum((lasso_eval[, 1] - lasso_eval[, 2])^2)
#rf_pred <- h2o.performance(models$rf, newdata = as.h2o(test_data))
#rf_pred <- as.data.frame(predict(object = models$rf, newdata = as.h2o(test_data[, -1])))
#rf_eval <- data.frame(rf_pred, test_data[, 1])
#rf_mse <- 1/100 * sum((rf_eval[, 1] - rf_eval[, 2])^2)
#rf_eval[3] <- lasso_eval[1]
#colnames(rf_eval) <- c("rf", "true", "lasso")
system.time(dat <- monte_carlo(n = 300,
p = 10,
type = "symmetric",
corr = 0.5,
sd = 1,
iterations = 1,
seed = 1
))
View(dat)
# monte-carlo.r
# Gabe Ackall, Seongtae Kim, Connor Shrader
# This file contains everything to be executed using the functions from
# simulation.r and metrics.r.
# R version: 4.1.0
library(tidyverse) # v1.3.1
library(dplyr) # v1.0.6
library(faux) # v1.0.0
library(ncvreg) # v3.13.0
library(glmnet) # v4.1-1
# Used for stepwise selection.
library(MASS) # v7.3-54
# Used for confusion matrices.
library(caret) # v6.0-88
# Used to set the current working directory to this script.
library(rstudioapi) # v0.13
library(bit64) # v4.0.5
# Used for XGBoost models.
library(xgboost) # v1.4.1.1
# Used for random forest models.
library(ranger) # v0.12.1
# Support vector machine model
library(e1071) # v1.7-7
setwd(dirname(getActiveDocumentContext()$path))
source("simulation.r")
source("metrics.r")
#random_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#models <- fit_models(dat = random_data, n = 100, p = 10)
#test_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#lasso_pred <- predict(models$lasso, as.matrix(test_data[, -1]))
#lasso_eval <- data.frame(lasso_pred, test_data[, 1])
#lasso_mse <- 1/100 * sum((lasso_eval[, 1] - lasso_eval[, 2])^2)
#rf_pred <- h2o.performance(models$rf, newdata = as.h2o(test_data))
#rf_pred <- as.data.frame(predict(object = models$rf, newdata = as.h2o(test_data[, -1])))
#rf_eval <- data.frame(rf_pred, test_data[, 1])
#rf_mse <- 1/100 * sum((rf_eval[, 1] - rf_eval[, 2])^2)
#rf_eval[3] <- lasso_eval[1]
#colnames(rf_eval) <- c("rf", "true", "lasso")
system.time(dat <- monte_carlo(n = 300,
p = 10,
type = "symmetric",
corr = 0.5,
sd = 1,
iterations = 1,
seed = 1
))
View(dat)
#setup
library(MASS) #used for Boston dataframe
library(gcdnet) #used for adaptive elastic net regression
library(glmnet) #used for lasso regression
library(tidyverse) #data cleaning and analysis
set.seed(23122) #set seed to keep consistent results
nrows <- nrow(Boston)
train <- sample(1:nrow(Boston),size=round(nrows*.75))  #seperate 75% into training data
######Separating data#####
train_x_data <-  as.matrix(Boston[train, 1:length(Boston)-1])  #training x data
train_y_data <- as.matrix(Boston[train, "medv"])  #training y data (AKA labels)
test_x_data <- as.matrix(Boston[-train, 1:length(Boston)-1])
test_y_data <- Boston[-train, "medv"]
adap_enet <- cv.gcdnet(x = train_x_data, y = train_y_data, nfolds = 10, method = "ls")
adap_enet_yhat <- predict(adap_enet, newx = test_x_data)
adap_enet_mse <- mean((adap_enet_yhat - test_y_data)^2)
time <- system.time(lasso <- cv.glmnet(x = train_x_data, y = train_y_data, alpha = 1))
lasso_yhat <- predict(lasso, newx = test_x_data)
lasso_mse <- mean((lasso_yhat - test_y_data)^2)
time
time[1]
time$user
time[2]
time[3]
?system.time
# monte-carlo.r
# Gabe Ackall, Seongtae Kim, Connor Shrader
# This file contains everything to be executed using the functions from
# simulation.r and metrics.r.
# R version: 4.1.0
library(tidyverse) # v1.3.1
library(dplyr) # v1.0.6
library(faux) # v1.0.0
library(ncvreg) # v3.13.0
library(glmnet) # v4.1-1
library(gcdnet) #v1.0.5
# Used for stepwise selection.
library(MASS) # v7.3-54
# Used for confusion matrices.
library(caret) # v6.0-88
# Used to set the current working directory to this script.
library(rstudioapi) # v0.13
library(bit64) # v4.0.5
# Used for XGBoost models.
library(xgboost) # v1.4.1.1
# Used for random forest models.
library(ranger) # v0.12.1
# Support vector machine model
library(e1071) # v1.7-7
setwd(dirname(getActiveDocumentContext()$path))
source("simulation.r")
source("metrics.r")
#random_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#models <- fit_models(dat = random_data, n = 100, p = 10)
#test_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#lasso_pred <- predict(models$lasso, as.matrix(test_data[, -1]))
#lasso_eval <- data.frame(lasso_pred, test_data[, 1])
#lasso_mse <- 1/100 * sum((lasso_eval[, 1] - lasso_eval[, 2])^2)
#rf_pred <- h2o.performance(models$rf, newdata = as.h2o(test_data))
#rf_pred <- as.data.frame(predict(object = models$rf, newdata = as.h2o(test_data[, -1])))
#rf_eval <- data.frame(rf_pred, test_data[, 1])
#rf_mse <- 1/100 * sum((rf_eval[, 1] - rf_eval[, 2])^2)
#rf_eval[3] <- lasso_eval[1]
#colnames(rf_eval) <- c("rf", "true", "lasso")
system.time(dat <- monte_carlo(n = 50,
p = 100,
type = "symmetric",
corr = 0.5,
sd = 1,
iterations = 1,
seed = 1
))
View(dat)
# monte-carlo.r
# Gabe Ackall, Seongtae Kim, Connor Shrader
# This file contains everything to be executed using the functions from
# simulation.r and metrics.r.
# R version: 4.1.0
library(tidyverse) # v1.3.1
library(dplyr) # v1.0.6
library(faux) # v1.0.0
library(ncvreg) # v3.13.0
library(glmnet) # v4.1-1
library(gcdnet) #v1.0.5
# Used for stepwise selection.
library(MASS) # v7.3-54
# Used for confusion matrices.
library(caret) # v6.0-88
# Used to set the current working directory to this script.
library(rstudioapi) # v0.13
library(bit64) # v4.0.5
# Used for XGBoost models.
library(xgboost) # v1.4.1.1
# Used for random forest models.
library(ranger) # v0.12.1
# Support vector machine model
library(e1071) # v1.7-7
setwd(dirname(getActiveDocumentContext()$path))
source("simulation.r")
source("metrics.r")
#random_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#models <- fit_models(dat = random_data, n = 100, p = 10)
#test_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#lasso_pred <- predict(models$lasso, as.matrix(test_data[, -1]))
#lasso_eval <- data.frame(lasso_pred, test_data[, 1])
#lasso_mse <- 1/100 * sum((lasso_eval[, 1] - lasso_eval[, 2])^2)
#rf_pred <- h2o.performance(models$rf, newdata = as.h2o(test_data))
#rf_pred <- as.data.frame(predict(object = models$rf, newdata = as.h2o(test_data[, -1])))
#rf_eval <- data.frame(rf_pred, test_data[, 1])
#rf_mse <- 1/100 * sum((rf_eval[, 1] - rf_eval[, 2])^2)
#rf_eval[3] <- lasso_eval[1]
#colnames(rf_eval) <- c("rf", "true", "lasso")
system.time(dat <- monte_carlo(n = 50,
p = 100,
type = "symmetric",
corr = 0.5,
sd = 1,
iterations = 1,
seed = 1
))
View(dat)
View(dat[[1]][["coefficients"]])
#setup
library(MASS) #used for Boston dataframe
library(gcdnet) #used for adaptive elastic net regression
library(glmnet) #used for lasso regression
library(tidyverse) #data cleaning and analysis
set.seed(23122) #set seed to keep consistent results
nrows <- nrow(Boston)
train <- sample(1:nrow(Boston),size=round(nrows*.75))  #seperate 75% into training data
######Separating data#####
train_x_data <-  as.matrix(Boston[train, 1:length(Boston)-1])  #training x data
train_y_data <- as.matrix(Boston[train, "medv"])  #training y data (AKA labels)
test_x_data <- as.matrix(Boston[-train, 1:length(Boston)-1])
test_y_data <- Boston[-train, "medv"]
adap_enet <- cv.gcdnet(x = train_x_data, y = train_y_data, nfolds = 10, method = "ls")
adap_enet_yhat <- predict(adap_enet, newx = test_x_data)
adap_enet_mse <- mean((adap_enet_yhat - test_y_data)^2)
time <- system.time(lasso <- cv.glmnet(x = train_x_data, y = train_y_data, alpha = 1))
lasso_yhat <- predict(lasso, newx = test_x_data)
lasso_mse <- mean((lasso_yhat - test_y_data)^2)
coef(adap_enet)
# monte-carlo.r
# Gabe Ackall, Seongtae Kim, Connor Shrader
# This file contains everything to be executed using the functions from
# simulation.r and metrics.r.
# R version: 4.1.0
library(tidyverse) # v1.3.1
library(dplyr) # v1.0.6
library(faux) # v1.0.0
library(ncvreg) # v3.13.0
library(glmnet) # v4.1-1
library(gcdnet) #v1.0.5
# Used for stepwise selection.
library(MASS) # v7.3-54
# Used for confusion matrices.
library(caret) # v6.0-88
# Used to set the current working directory to this script.
library(rstudioapi) # v0.13
library(bit64) # v4.0.5
# Used for XGBoost models.
library(xgboost) # v1.4.1.1
# Used for random forest models.
library(ranger) # v0.12.1
# Support vector machine model
library(e1071) # v1.7-7
setwd(dirname(getActiveDocumentContext()$path))
source("simulation.r")
source("metrics.r")
#random_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#models <- fit_models(dat = random_data, n = 100, p = 10)
#test_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#lasso_pred <- predict(models$lasso, as.matrix(test_data[, -1]))
#lasso_eval <- data.frame(lasso_pred, test_data[, 1])
#lasso_mse <- 1/100 * sum((lasso_eval[, 1] - lasso_eval[, 2])^2)
#rf_pred <- h2o.performance(models$rf, newdata = as.h2o(test_data))
#rf_pred <- as.data.frame(predict(object = models$rf, newdata = as.h2o(test_data[, -1])))
#rf_eval <- data.frame(rf_pred, test_data[, 1])
#rf_mse <- 1/100 * sum((rf_eval[, 1] - rf_eval[, 2])^2)
#rf_eval[3] <- lasso_eval[1]
#colnames(rf_eval) <- c("rf", "true", "lasso")
system.time(dat <- monte_carlo(n = 50,
p = 100,
type = "symmetric",
corr = 0.5,
sd = 1,
iterations = 1,
seed = 1
))
View(dat)
View(dat[[1]][["coefficients"]])
coef(lasso)
coef(adap_enet)
matrix(coef(adap_enet))
matrix(coef(lasso))
test_list <- list()
test_list[['yay']] <- "hi"
View(test_list)
View(test_list)
View(test_list)
# monte-carlo.r
# Gabe Ackall, Seongtae Kim, Connor Shrader
# This file contains everything to be executed using the functions from
# simulation.r and metrics.r.
# R version: 4.1.0
library(tidyverse) # v1.3.1
library(dplyr) # v1.0.6
library(faux) # v1.0.0
library(ncvreg) # v3.13.0
library(glmnet) # v4.1-1
library(gcdnet) #v1.0.5
# Used for stepwise selection.
library(MASS) # v7.3-54
# Used for confusion matrices.
library(caret) # v6.0-88
# Used to set the current working directory to this script.
library(rstudioapi) # v0.13
library(bit64) # v4.0.5
# Used for XGBoost models.
library(xgboost) # v1.4.1.1
# Used for random forest models.
library(ranger) # v0.12.1
# Support vector machine model
library(e1071) # v1.7-7
setwd(dirname(getActiveDocumentContext()$path))
source("simulation.r")
source("metrics.r")
#random_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#models <- fit_models(dat = random_data, n = 100, p = 10)
#test_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#lasso_pred <- predict(models$lasso, as.matrix(test_data[, -1]))
#lasso_eval <- data.frame(lasso_pred, test_data[, 1])
#lasso_mse <- 1/100 * sum((lasso_eval[, 1] - lasso_eval[, 2])^2)
#rf_pred <- h2o.performance(models$rf, newdata = as.h2o(test_data))
#rf_pred <- as.data.frame(predict(object = models$rf, newdata = as.h2o(test_data[, -1])))
#rf_eval <- data.frame(rf_pred, test_data[, 1])
#rf_mse <- 1/100 * sum((rf_eval[, 1] - rf_eval[, 2])^2)
#rf_eval[3] <- lasso_eval[1]
#colnames(rf_eval) <- c("rf", "true", "lasso")
system.time(dat <- monte_carlo(n = 50,
p = 100,
type = "symmetric",
corr = 0.5,
sd = 1,
iterations = 1,
seed = 1
))
View(dat)
# monte-carlo.r
# Gabe Ackall, Seongtae Kim, Connor Shrader
# This file contains everything to be executed using the functions from
# simulation.r and metrics.r.
# R version: 4.1.0
library(tidyverse) # v1.3.1
library(dplyr) # v1.0.6
library(faux) # v1.0.0
library(ncvreg) # v3.13.0
library(glmnet) # v4.1-1
library(gcdnet) #v1.0.5
# Used for stepwise selection.
library(MASS) # v7.3-54
# Used for confusion matrices.
library(caret) # v6.0-88
# Used to set the current working directory to this script.
library(rstudioapi) # v0.13
library(bit64) # v4.0.5
# Used for XGBoost models.
library(xgboost) # v1.4.1.1
# Used for random forest models.
library(ranger) # v0.12.1
# Support vector machine model
library(e1071) # v1.7-7
setwd(dirname(getActiveDocumentContext()$path))
source("simulation.r")
source("metrics.r")
#random_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#models <- fit_models(dat = random_data, n = 100, p = 10)
#test_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#lasso_pred <- predict(models$lasso, as.matrix(test_data[, -1]))
#lasso_eval <- data.frame(lasso_pred, test_data[, 1])
#lasso_mse <- 1/100 * sum((lasso_eval[, 1] - lasso_eval[, 2])^2)
#rf_pred <- h2o.performance(models$rf, newdata = as.h2o(test_data))
#rf_pred <- as.data.frame(predict(object = models$rf, newdata = as.h2o(test_data[, -1])))
#rf_eval <- data.frame(rf_pred, test_data[, 1])
#rf_mse <- 1/100 * sum((rf_eval[, 1] - rf_eval[, 2])^2)
#rf_eval[3] <- lasso_eval[1]
#colnames(rf_eval) <- c("rf", "true", "lasso")
system.time(dat <- monte_carlo(n = 100,
p = 10,
type = "symmetric",
corr = 0.5,
sd = 1,
iterations = 1,
seed = 1
))
View(dat)
# monte-carlo.r
# Gabe Ackall, Seongtae Kim, Connor Shrader
# This file contains everything to be executed using the functions from
# simulation.r and metrics.r.
# R version: 4.1.0
library(tidyverse) # v1.3.1
library(dplyr) # v1.0.6
library(faux) # v1.0.0
library(ncvreg) # v3.13.0
library(glmnet) # v4.1-1
library(gcdnet) #v1.0.5
# Used for stepwise selection.
library(MASS) # v7.3-54
# Used for confusion matrices.
library(caret) # v6.0-88
# Used to set the current working directory to this script.
library(rstudioapi) # v0.13
library(bit64) # v4.0.5
# Used for XGBoost models.
library(xgboost) # v1.4.1.1
# Used for random forest models.
library(ranger) # v0.12.1
# Support vector machine model
library(e1071) # v1.7-7
setwd(dirname(getActiveDocumentContext()$path))
source("simulation.r")
source("metrics.r")
#random_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#models <- fit_models(dat = random_data, n = 100, p = 10)
#test_data <- generate_data(seed = 1, n = 100, p = 10, corr = 0, type = "independent")
#lasso_pred <- predict(models$lasso, as.matrix(test_data[, -1]))
#lasso_eval <- data.frame(lasso_pred, test_data[, 1])
#lasso_mse <- 1/100 * sum((lasso_eval[, 1] - lasso_eval[, 2])^2)
#rf_pred <- h2o.performance(models$rf, newdata = as.h2o(test_data))
#rf_pred <- as.data.frame(predict(object = models$rf, newdata = as.h2o(test_data[, -1])))
#rf_eval <- data.frame(rf_pred, test_data[, 1])
#rf_mse <- 1/100 * sum((rf_eval[, 1] - rf_eval[, 2])^2)
#rf_eval[3] <- lasso_eval[1]
#colnames(rf_eval) <- c("rf", "true", "lasso")
system.time(dat <- monte_carlo(n = 100,
p = 10,
type = "symmetric",
corr = 0.5,
sd = 1,
iterations = 1,
seed = 1
))
View(dat)
library(gcdnet) #v1.0.5
?gcdnet
library(ncvreg) # v3.13.0
library(glmnet) # v4.1-1
?glmnet
?ncvreg
