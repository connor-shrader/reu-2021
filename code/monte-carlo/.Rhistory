<<<<<<< HEAD
glm.fit=glm(Gender_0M_1F~.-age-ID, data=glm_train_set,family=binomial)
glm.probs=predict(glm.fit,glm_test_set,type="response")
glm.pred=rep("0",length(test.ID))
glm.pred[glm.probs>.5]="1"
table(glm.pred, glm_test_set$Gender_0M_1F) ## confusion table
Accuracy=mean(glm.pred==glm_test_set$Gender_0M_1F) ## Prediction Accuracy
OUT.glm=c(OUT.glm, Accuracy)
GTRUE = c(GTRUE, glm_test_set$Gender_0M_1F)
GPRED= c(GPRED, glm.pred)
}
print(OUT.glm)
mean(OUT.glm)
Confusion.Table=table(GPRED,GTRUE);
print(Confusion.Table)
glm.cv.sensitivity <- mean((GTRUE == GPRED)[GTRUE == 1])
glm.cv.sensitivity
glm.cv.specificity <- mean((GTRUE == GPRED)[GTRUE == 0])
glm.cv.specificity
end.time <- Sys.time()
time.taken <- end.time - start.time
#5fold CV LDA
start.time <- Sys.time()
set.seed(52)
n=dim(fgnet_full)[1]; m=dim(fgnet_full)[2]
n_fold<-5; # number of cross validations #
#rep(1:n_fold, length.out = n)
folds_i <- sample(rep(1:n_fold, length.out = n)) ##without replacement
table(folds_i)
OUT.lda=NULL
GTRUE = NULL; GPRED=NULL;
for (k in 1:n_fold)
{
test.ID <- which(folds_i == k)
lda_train_set <- fgnet_full[-test.ID, ]
lda_test_set <- fgnet_full[test.ID, ]
lda.fit=lda(Gender_0M_1F~.-age-ID, data=lda_train_set)
lda.probs=predict(lda.fit, lda_test_set)
lda.probs
lda.class=lda.probs$class
table(lda.class, lda_test_set$Gender_0M_1F) ## confusion table
Accuracy=mean(lda.class==lda_test_set$Gender_0M_1F) ## Prediction Accuracy
OUT.lda=c(OUT.lda, Accuracy)
GTRUE = c(GTRUE, factor(lda_test_set$Gender_0M_1F))
GPRED= c(GPRED, lda.class)
}
print(OUT.lda)
mean(OUT.lda)
Confusion.Table=table(GPRED,GTRUE);
print(Confusion.Table)
lda.cv.sensitivity <- mean((GTRUE == GPRED)[GTRUE == 2])
lda.cv.sensitivity
lda.cv.specificity <- mean((GTRUE == GPRED)[GTRUE == 1])
lda.cv.specificity
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
#5fold CV QDA
start.time <- Sys.time()
set.seed(52)
n=dim(fgnet_full)[1]; m=dim(fgnet_full)[2]
n_fold<-5; # number of cross validations #
#rep(1:n_fold, length.out = n)
folds_i <- sample(rep(1:n_fold, length.out = n)) ##without replacement
table(folds_i)
OUT.qda=NULL
GTRUE = NULL; GPRED=NULL;
for (k in 1:n_fold)
{
test.ID <- which(folds_i == k)
qda_train_set <- fgnet_full[-test.ID, ]
qda_test_set <- fgnet_full[test.ID, ]
qda.fit=qda(Gender_0M_1F~.-age-ID, data=qda_train_set)
qda.probs=predict(qda.fit, qda_test_set)
qda.probs
qda.class=qda.probs$class
table(qda.class, qda_test_set$Gender_0M_1F) ## confusion table
Accuracy=mean(qda.class==qda_test_set$Gender_0M_1F) ## Prediction Accuracy
OUT.qda=c(OUT.qda, Accuracy)
GTRUE = c(GTRUE, factor(qda_test_set$Gender_0M_1F))
GPRED= c(GPRED, qda.class)
}
print(OUT.qda)
mean(OUT.qda)
Confusion.Table=table(GPRED,GTRUE);
print(Confusion.Table)
qda.cv.sensitivity <- mean((GTRUE == GPRED)[GTRUE == 2])
qda.cv.sensitivity
qda.cv.specificity <- mean((GTRUE == GPRED)[GTRUE == 1])
qda.cv.specificity
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
#KNN5-CV Boxplot
knn.cv.5 <- c(0.7263682, 0.7064677, 0.6750000, 0.6850000, 0.6750000)
log.cv <- c(0.7960199, 0.8407960, 0.8400000, 0.7600000, 0.8250000)
lda.cv <- c(0.7711443, 0.8159204, 0.8700000, 0.7800000, 0.8400000)
qda.cv <- c(0.8159204, 0.8507463, 0.7850000, 0.8450000, 0.8700000)
boxplotdata <- cbind(cbind(cbind(data.frame(knn.cv.5),log.cv),lda.cv), qda.cv)
boxplot(knn.cv.5, col = "lightblue", ylab = "Accuracy", names = c("KNN", "GLM", "LDA", "QDA"))
#KNN5-CV Boxplot
knn.cv.5 <- c(0.7263682, 0.7064677, 0.6750000, 0.6850000, 0.6750000)
log.cv <- c(0.7960199, 0.8407960, 0.8400000, 0.7600000, 0.8250000)
lda.cv <- c(0.7711443, 0.8159204, 0.8700000, 0.7800000, 0.8400000)
qda.cv <- c(0.8159204, 0.8507463, 0.7850000, 0.8450000, 0.8700000)
boxplotdata <- cbind(cbind(cbind(data.frame(knn.cv.5),log.cv),lda.cv), qda.cv)
boxplot(boxplotdata, col = "lightblue", ylab = "Accuracy", names = c("KNN", "GLM", "LDA", "QDA"))
#5fold knn
start.time <- Sys.time()
set.seed(52)
rows = dim(fgnet_full)[1]
n_fold = 5
folds_i = sample(rep(1:n_fold, length.out = rows))
for(k_value in 3:7){ #loops through k values
OUT.KNN = NULL
knn.total.pred <- NULL
for(k in 1:n_fold){ #loops through folds
#assigning test and train sets
test.ID = which(folds_i == k)
train_x = fgnet_full[-test.ID, 1:109]
train_y = fgnet_full[-test.ID, 112]
test_x = fgnet_full[test.ID, 1:109]
test_y = fgnet_full[test.ID, 112]
#constructing model
knn.pred = knn(train_x, test_x, train_y, k = k_value)
knn.total.pred <- c(knn.total.pred, knn.pred)
#calculating accuracy and saving it to the OUT.NULL list
accuracy = mean(knn.pred == test_y)
OUT.KNN = c(OUT.KNN, accuracy)
}
print("K = "); print(k_value)
print(OUT.KNN)#all five accuracies
tableknn <- table(knn.total.pred, fgnet_full[,112])
print(tableknn)
print(mean(OUT.KNN)) #overall accuracy for one k value
print(sd(OUT.KNN)) #sd for one k value
print(sum(tableknn[2,2])/(sum(tableknn[1,2])+sum(tableknn[2,2])))#Sensitivity
print(sum(tableknn[2,1])/(sum(tableknn[1,1])+sum(tableknn[2,1])))#Specificity
}
end.time <- Sys.time()
time.taken <- end.time - start.time
#5fold knn
start.time <- Sys.time()
set.seed(52)
rows = dim(fgnet_full)[1]
n_fold = 5
folds_i = sample(rep(1:n_fold, length.out = rows))
for(k_value in 3:7){ #loops through k values
OUT.KNN = NULL
knn.total.pred <- NULL
for(k in 1:n_fold){ #loops through folds
#assigning test and train sets
test.ID = which(folds_i == k)
train_x = fgnet_full[-test.ID, 1:109]
train_y = fgnet_full[-test.ID, 112]
test_x = fgnet_full[test.ID, 1:109]
test_y = fgnet_full[test.ID, 112]
#constructing model
knn.pred = knn(train_x, test_x, train_y, k = k_value)
knn.total.pred <- c(knn.total.pred, knn.pred)
#calculating accuracy and saving it to the OUT.NULL list
accuracy = mean(knn.pred == test_y)
OUT.KNN = c(OUT.KNN, accuracy)
}
print("K = "); print(k_value)
print(OUT.KNN)#all five accuracies
tableknn <- table(knn.total.pred, fgnet_full[,112])
print(tableknn)
print(mean(OUT.KNN)) #overall accuracy for one k value
print(sd(OUT.KNN)) #sd for one k value
print(sum(tableknn[2,2])/(sum(tableknn[1,2])+sum(tableknn[2,2])))#Sensitivity
print(sum(tableknn[2,1])/(sum(tableknn[1,1])+sum(tableknn[2,1])))#Specificity
}
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken
time.taken
#KNN5-CV Boxplot
knn.cv.5 <- c(0.7263682, 0.7064677, 0.6750000, 0.6850000, 0.6750000)
log.cv <- c(0.7960199, 0.8407960, 0.8400000, 0.7600000, 0.8250000)
lda.cv <- c(0.7711443, 0.8159204, 0.8700000, 0.7800000, 0.8400000)
qda.cv <- c(0.8159204, 0.8507463, 0.7850000, 0.8450000, 0.8700000)
boxplotdata <- cbind(cbind(cbind(data.frame(knn.cv.5),log.cv),lda.cv), qda.cv)
boxplot(boxplotdata, col = "deepskyblue1", ylab = "Accuracy", names = c("KNN", "GLM", "LDA", "QDA"))
#KNN5-CV Boxplot
knn.cv.5 <- c(0.7263682, 0.7064677, 0.6750000, 0.6850000, 0.6750000)
log.cv <- c(0.7960199, 0.8407960, 0.8400000, 0.7600000, 0.8250000)
lda.cv <- c(0.7711443, 0.8159204, 0.8700000, 0.7800000, 0.8400000)
qda.cv <- c(0.8159204, 0.8507463, 0.7850000, 0.8450000, 0.8700000)
boxplotdata <- cbind(cbind(cbind(data.frame(knn.cv.5),log.cv),lda.cv), qda.cv)
boxplot(boxplotdata, col = "dodgerblue", ylab = "Accuracy", names = c("KNN", "GLM", "LDA", "QDA"))
#KNN5-CV Boxplot
knn.cv.5 <- c(0.7263682, 0.7064677, 0.6750000, 0.6850000, 0.6750000)
log.cv <- c(0.7960199, 0.8407960, 0.8400000, 0.7600000, 0.8250000)
lda.cv <- c(0.7711443, 0.8159204, 0.8700000, 0.7800000, 0.8400000)
qda.cv <- c(0.8159204, 0.8507463, 0.7850000, 0.8450000, 0.8700000)
boxplotdata <- cbind(cbind(cbind(data.frame(knn.cv.5),log.cv),lda.cv), qda.cv)
boxplot(boxplotdata, col = "blue", alpha = 0.7, ylab = "Accuracy", names = c("KNN", "GLM", "LDA", "QDA"))
#KNN5-CV Boxplot
knn.cv.5 <- c(0.7263682, 0.7064677, 0.6750000, 0.6850000, 0.6750000)
log.cv <- c(0.7960199, 0.8407960, 0.8400000, 0.7600000, 0.8250000)
lda.cv <- c(0.7711443, 0.8159204, 0.8700000, 0.7800000, 0.8400000)
qda.cv <- c(0.8159204, 0.8507463, 0.7850000, 0.8450000, 0.8700000)
boxplotdata <- cbind(cbind(cbind(data.frame(knn.cv.5),log.cv),lda.cv), qda.cv)
boxplot(boxplotdata, col = "blue", alpha = 0.4, ylab = "Accuracy", names = c("KNN", "GLM", "LDA", "QDA"))
#KNN5-CV Boxplot
knn.cv.5 <- c(0.7263682, 0.7064677, 0.6750000, 0.6850000, 0.6750000)
log.cv <- c(0.7960199, 0.8407960, 0.8400000, 0.7600000, 0.8250000)
lda.cv <- c(0.7711443, 0.8159204, 0.8700000, 0.7800000, 0.8400000)
qda.cv <- c(0.8159204, 0.8507463, 0.7850000, 0.8450000, 0.8700000)
boxplotdata <- cbind(cbind(cbind(data.frame(knn.cv.5),log.cv),lda.cv), qda.cv)
boxplot(boxplotdata, col = "blue", alpha = 0.2, ylab = "Accuracy", names = c("KNN", "GLM", "LDA", "QDA"))
#KNN5-CV Boxplot
knn.cv.5 <- c(0.7263682, 0.7064677, 0.6750000, 0.6850000, 0.6750000)
log.cv <- c(0.7960199, 0.8407960, 0.8400000, 0.7600000, 0.8250000)
lda.cv <- c(0.7711443, 0.8159204, 0.8700000, 0.7800000, 0.8400000)
qda.cv <- c(0.8159204, 0.8507463, 0.7850000, 0.8450000, 0.8700000)
boxplotdata <- cbind(cbind(cbind(data.frame(knn.cv.5),log.cv),lda.cv), qda.cv)
boxplot(boxplotdata, col = "blue", bg = "dodgerblue", ylab = "Accuracy", names = c("KNN", "GLM", "LDA", "QDA"))
#KNN5-CV Boxplot
knn.cv.5 <- c(0.7263682, 0.7064677, 0.6750000, 0.6850000, 0.6750000)
log.cv <- c(0.7960199, 0.8407960, 0.8400000, 0.7600000, 0.8250000)
lda.cv <- c(0.7711443, 0.8159204, 0.8700000, 0.7800000, 0.8400000)
qda.cv <- c(0.8159204, 0.8507463, 0.7850000, 0.8450000, 0.8700000)
boxplotdata <- cbind(cbind(cbind(data.frame(knn.cv.5),log.cv),lda.cv), qda.cv)
boxplot(boxplotdata, col = "blue", bg = "dodgerblue1", ylab = "Accuracy", names = c("KNN", "GLM", "LDA", "QDA"))
#KNN5-CV Boxplot
knn.cv.5 <- c(0.7263682, 0.7064677, 0.6750000, 0.6850000, 0.6750000)
log.cv <- c(0.7960199, 0.8407960, 0.8400000, 0.7600000, 0.8250000)
lda.cv <- c(0.7711443, 0.8159204, 0.8700000, 0.7800000, 0.8400000)
qda.cv <- c(0.8159204, 0.8507463, 0.7850000, 0.8450000, 0.8700000)
boxplotdata <- cbind(cbind(cbind(data.frame(knn.cv.5),log.cv),lda.cv), qda.cv)
boxplot(boxplotdata, bg = "dodgerblue1", ylab = "Accuracy", names = c("KNN", "GLM", "LDA", "QDA"))
#KNN5-CV Boxplot
knn.cv.5 <- c(0.7263682, 0.7064677, 0.6750000, 0.6850000, 0.6750000)
log.cv <- c(0.7960199, 0.8407960, 0.8400000, 0.7600000, 0.8250000)
lda.cv <- c(0.7711443, 0.8159204, 0.8700000, 0.7800000, 0.8400000)
qda.cv <- c(0.8159204, 0.8507463, 0.7850000, 0.8450000, 0.8700000)
boxplotdata <- cbind(cbind(cbind(data.frame(knn.cv.5),log.cv),lda.cv), qda.cv)
boxplot(boxplotdata, col = "dodgerblue",  ylab = "Accuracy", names = c("KNN", "GLM", "LDA", "QDA"))
#lopo-cv knn
start.time <- Sys.time()
set.seed(52)
for(k_value in 3:7){ #loops through k values
OUT.KNN = NULL
knn.total.pred = NULL
for(i in 1:82){ #loops through IDs
LOPO_train <- filter(fgnet_full, ID != i)
LOPO_test <- filter(fgnet_full, ID == i)
#assigning test and train sets
train_x = LOPO_train[, 1:109]
train_y = LOPO_train[, 112 ]
test_x = LOPO_test[, 1:109]
test_y = LOPO_test[, 112]
#constructing model
knn.pred = knn(train_x, test_x, train_y, k = k_value)
knn.total.pred <- c(knn.total.pred, knn.pred)
#calculating accuracy and saving it to the OUT.NULL list
accuracy = mean(knn.pred == test_y)
OUT.KNN = c(OUT.KNN, accuracy)
}
print("K = "); print(k_value)
print(mean(OUT.KNN)) #overall accuracy for one k value
print(sd(OUT.KNN)) #sd for one k value
tableknn <- table(knn.total.pred, fgnet_full[,112])
print(tableknn)
print(sum(tableknn[2,2])/(sum(tableknn[1,2])+sum(tableknn[2,2])))#Sensitivity
print(sum(tableknn[2,1])/(sum(tableknn[1,1])+sum(tableknn[2,1])))#Specificity
}
end.time <- Sys.time()
time.taken <- end.time - start.time
Time.taken #10.634 sec
#lopo-cv knn
start.time <- Sys.time()
set.seed(52)
for(k_value in 3:7){ #loops through k values
OUT.KNN = NULL
knn.total.pred = NULL
for(i in 1:82){ #loops through IDs
LOPO_train <- filter(fgnet_full, ID != i)
LOPO_test <- filter(fgnet_full, ID == i)
#assigning test and train sets
train_x = LOPO_train[, 1:109]
train_y = LOPO_train[, 112 ]
test_x = LOPO_test[, 1:109]
test_y = LOPO_test[, 112]
#constructing model
knn.pred = knn(train_x, test_x, train_y, k = k_value)
knn.total.pred <- c(knn.total.pred, knn.pred)
#calculating accuracy and saving it to the OUT.NULL list
accuracy = mean(knn.pred == test_y)
OUT.KNN = c(OUT.KNN, accuracy)
}
print("K = "); print(k_value)
print(OUT.knn)
print(mean(OUT.KNN)) #overall accuracy for one k value
print(sd(OUT.KNN)) #sd for one k value
tableknn <- table(knn.total.pred, fgnet_full[,112])
print(tableknn)
print(sum(tableknn[2,2])/(sum(tableknn[1,2])+sum(tableknn[2,2])))#Sensitivity
print(sum(tableknn[2,1])/(sum(tableknn[1,1])+sum(tableknn[2,1])))#Specificity
}
#lopo-cv knn
start.time <- Sys.time()
set.seed(52)
for(k_value in 3:7){ #loops through k values
OUT.KNN = NULL
knn.total.pred = NULL
for(i in 1:82){ #loops through IDs
LOPO_train <- filter(fgnet_full, ID != i)
LOPO_test <- filter(fgnet_full, ID == i)
#assigning test and train sets
train_x = LOPO_train[, 1:109]
train_y = LOPO_train[, 112 ]
test_x = LOPO_test[, 1:109]
test_y = LOPO_test[, 112]
#constructing model
knn.pred = knn(train_x, test_x, train_y, k = k_value)
knn.total.pred <- c(knn.total.pred, knn.pred)
#calculating accuracy and saving it to the OUT.NULL list
accuracy = mean(knn.pred == test_y)
OUT.KNN = c(OUT.KNN, accuracy)
}
print("K = "); print(k_value)
print(OUT.KNN)
print(mean(OUT.KNN)) #overall accuracy for one k value
print(sd(OUT.KNN)) #sd for one k value
tableknn <- table(knn.total.pred, fgnet_full[,112])
print(tableknn)
print(sum(tableknn[2,2])/(sum(tableknn[1,2])+sum(tableknn[2,2])))#Sensitivity
print(sum(tableknn[2,1])/(sum(tableknn[1,1])+sum(tableknn[2,1])))#Specificity
}
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken #10.634 sec
#lopo-cv knn
start.time <- Sys.time()
set.seed(52)
for(k_value in 5:5){ #loops through k values
OUT.KNN = NULL
knn.total.pred = NULL
for(i in 1:82){ #loops through IDs
LOPO_train <- filter(fgnet_full, ID != i)
LOPO_test <- filter(fgnet_full, ID == i)
#assigning test and train sets
train_x = LOPO_train[, 1:109]
train_y = LOPO_train[, 112 ]
test_x = LOPO_test[, 1:109]
test_y = LOPO_test[, 112]
#constructing model
knn.pred = knn(train_x, test_x, train_y, k = k_value)
knn.total.pred <- c(knn.total.pred, knn.pred)
#calculating accuracy and saving it to the OUT.NULL list
accuracy = mean(knn.pred == test_y)
OUT.KNN = c(OUT.KNN, accuracy)
}
print("K = "); print(k_value)
print(OUT.KNN)
print(mean(OUT.KNN)) #overall accuracy for one k value
print(sd(OUT.KNN)) #sd for one k value
tableknn <- table(knn.total.pred, fgnet_full[,112])
print(tableknn)
print(sum(tableknn[2,2])/(sum(tableknn[1,2])+sum(tableknn[2,2])))#Sensitivity
print(sum(tableknn[2,1])/(sum(tableknn[1,1])+sum(tableknn[2,1])))#Specificity
}
end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken #10.634 sec
source('~/NSFREU/reu-2021/code/variable-selection/monte-carlo.r', echo=TRUE)
View(coefs_df)
coef(lasso)
n <- 100
p <- 10
b = c(1, 2, -2, 0, 0, 0.5, 3, rep(0, (p-6))) ## p-6 >= 0
x = cbind(1, matrix(rnorm(n*p), nrow = n, ncol = p))
y = x%*%b + rnorm(n)
?%*%
x
source('~/NSFREU/reu-2021/code/alternative-machine-learning/alternative-models.R', echo=TRUE)
?randomForest
?svm
source("~/NSFREU/reu-2021/code/monte-carlo/perform-simulations.r", echo=TRUE)
rm(list = ls())
library(rstudioapi) # v0.13
setwd(dirname(getActiveDocumentContext()$path))
source("simulation.r")
source("metrics.r")
# Load parameters from file
load("../../data/monte-carlo/factorial-design.Rdata")
run_simulations <- function(indices, iterations = 1, ...) {
results <- lapply(indices, function(i) {
message("Beginning to run row ", i, ".")
row <- parameters[i, ]
n <- row$n
p <- row$p
st_dev <- row$sigma
# Convert row$covar (which is a factor) to a character.
type <- as.character(row$covar)
corr <- row$rho
filename <- paste("../../results/monte-carlo/sim_results_",
n, "_",
p, "_",
st_dev, "_",
type, "_",
corr, ".rds", sep = "")
block_size <- 0
if (!file.exists(filename)) {
if (type == "blockwise") {
if (p == 10) {
block_size <- 5
}
else if (p == 100) {
block_size <- 25
}
else if (p == 2000) {
block_size <- 100
}
}
time_taken <- system.time(results <- monte_carlo(n = n,
p = p,
iterations = iterations,
st_dev = st_dev,
type = type,
corr = corr,
block_size = block_size,
...))
message("Finished running row ", i, " at ", Sys.time(), ". Time taken: ")
print(time_taken)
saveRDS(results, file = filename)
}
else {
warning(c("Results file already exists for row ", i, "."))
}
})
return(results)
}
source("~/NSFREU/reu-2021/code/monte-carlo/perform-simulations.r", echo=TRUE)
res <- run_simulations(indices = 10:17, iterations = 100, num_cores = 6)
source("~/NSFREU/reu-2021/code/monte-carlo/perform-simulations.r", echo=TRUE)
source("~/NSFREU/reu-2021/code/monte-carlo/perform-simulations.r", echo=TRUE)
source("~/NSFREU/reu-2021/code/alternative-machine-learning/alternative-models.R", echo=TRUE)
bm_boost <- gbm(medv ~ . ,data = Boston[train,],distribution = "gaussian",n.trees = 1000,
shrinkage = 0.01, interaction.depth = 4)
#summary(gbm_boost) #gives a table of Variable Importance and a plot of Variable Importance
gbm_mse <- mean((test_y_data - predict(gbm_boost, as.data.frame(test_x_data))) ^ 2)
# XGBoost Model using Tree Boosting
xgb_tree <- xgboost(data = train_x_data, label = train_y_data,
booster = "gbtree", #use decision trees
nrounds = 1000,  #number of boosting iterations
objective = "reg:squarederror",  #regression by RSS
early_stopping_rounds = 3,  #stops boosting early if mse doesnt improve after a certain number of rounds
max_depth = 6,  #maximum depth of the tree
eta = .25,  #determines learning rate. Lower: less overfitting, but more nrounds and slower computation
verbose = 0)  #whether to print information during boosting: 0 = nothing, 1 = some info, 2 = more info
xgb_tree_train_mse <- mean((test_y_data - predict(xgb_tree, test_x_data)) ^ 2)
gbm_boost <- gbm(medv ~ . ,data = Boston[train,],distribution = "gaussian",n.trees = 1000,
shrinkage = 0.01, interaction.depth = 4)
#summary(gbm_boost) #gives a table of Variable Importance and a plot of Variable Importance
gbm_mse <- mean((test_y_data - predict(gbm_boost, as.data.frame(test_x_data))) ^ 2)
# XGBoost Model using Tree Boosting
xgb_tree <- xgboost(data = train_x_data, label = train_y_data,
booster = "gbtree", #use decision trees
nrounds = 1000,  #number of boosting iterations
objective = "reg:squarederror",  #regression by RSS
early_stopping_rounds = 3,  #stops boosting early if mse doesnt improve after a certain number of rounds
max_depth = 4,  #maximum depth of the tree
eta = .25,  #determines learning rate. Lower: less overfitting, but more nrounds and slower computation
verbose = 0)  #whether to print information during boosting: 0 = nothing, 1 = some info, 2 = more info
xgb_tree_train_mse <- mean((test_y_data - predict(xgb_tree, test_x_data)) ^ 2)
gbm_boost <- gbm(medv ~ . ,data = Boston[train,],distribution = "gaussian",n.trees = 1000,
shrinkage = 0.01, interaction.depth = 4)
#summary(gbm_boost) #gives a table of Variable Importance and a plot of Variable Importance
gbm_mse <- mean((test_y_data - predict(gbm_boost, as.data.frame(test_x_data))) ^ 2)
# XGBoost Model using Tree Boosting
xgb_tree <- xgboost(data = train_x_data, label = train_y_data,
booster = "gbtree", #use decision trees
nrounds = 1000,  #number of boosting iterations
objective = "reg:squarederror",  #regression by RSS
#early_stopping_rounds = 3,  #stops boosting early if mse doesnt improve after a certain number of rounds
max_depth = 4,  #maximum depth of the tree
eta = .25,  #determines learning rate. Lower: less overfitting, but more nrounds and slower computation
verbose = 0)  #whether to print information during boosting: 0 = nothing, 1 = some info, 2 = more info
xgb_tree_train_mse <- mean((test_y_data - predict(xgb_tree, test_x_data)) ^ 2)
#basic GBM
gbm_boost <- gbm(medv ~ . ,data = Boston[train,],distribution = "gaussian",n.trees = 1000,
shrinkage = 0, interaction.depth = 4)
#summary(gbm_boost) #gives a table of Variable Importance and a plot of Variable Importance
gbm_mse <- mean((test_y_data - predict(gbm_boost, as.data.frame(test_x_data))) ^ 2)
# XGBoost Model using Tree Boosting
xgb_tree <- xgboost(data = train_x_data, label = train_y_data,
booster = "gbtree", #use decision trees
nrounds = 1000,  #number of boosting iterations
objective = "reg:squarederror",  #regression by RSS
#early_stopping_rounds = 3,  #stops boosting early if mse doesnt improve after a certain number of rounds
max_depth = 4,  #maximum depth of the tree
eta = .25,  #determines learning rate. Lower: less overfitting, but more nrounds and slower computation
verbose = 0)  #whether to print information during boosting: 0 = nothing, 1 = some info, 2 = more info
xgb_tree_train_mse <- mean((test_y_data - predict(xgb_tree, test_x_data)) ^ 2)
?gbm
gbm_boost <- gbm(medv ~ . ,data = Boston[train,],distribution = "gaussian",n.trees = 1000,
shrinkage = 0.1, interaction.depth = 4)
#summary(gbm_boost) #gives a table of Variable Importance and a plot of Variable Importance
gbm_mse <- mean((test_y_data - predict(gbm_boost, as.data.frame(test_x_data))) ^ 2)
# XGBoost Model using Tree Boosting
xgb_tree <- xgboost(data = train_x_data, label = train_y_data,
booster = "gbtree", #use decision trees
nrounds = 1000,  #number of boosting iterations
objective = "reg:squarederror",  #regression by RSS
#early_stopping_rounds = 3,  #stops boosting early if mse doesnt improve after a certain number of rounds
max_depth = 4,  #maximum depth of the tree
eta = .25,  #determines learning rate. Lower: less overfitting, but more nrounds and slower computation
verbose = 0)  #whether to print information during boosting: 0 = nothing, 1 = some info, 2 = more info
xgb_tree_train_mse <- mean((test_y_data - predict(xgb_tree, test_x_data)) ^ 2)
=======
install.packages(tidyverse, dplyr, faux)
install.packages(c("tidyverse", "dplyr", "faux")
)
install.packages("ncvreg", "glmnet", "gcdnet", "MASS", "caret")
install.packages(c("ncvreg", "glmnet", "gcdnet", "MASS", "caret"))
install.packages(c("xgboost", "ranger", "e1071", "parallel"))
library(tidyverse)
require(devtools)
install.packages("devtools")
require(devtools)
install_version("dplyr", version = "1.0.6")
install_version("dplyr", version = "1.0.6")
detach("package:dplyr", unload = TRUE)
remove.packages("dplyr", lib="~/R/win-library/4.1")
install_version("dplyr", version = "1.0.6")
install_version("dplyr", version = "1.0.6", repos = "https://cran.r-project.org/src/contrib/Archive/dplyr/dplyr_1.0.6.tar.gz")
install_version("dplyr", version = "1.0.6", repos = "https://cran.r-project.org/")
install_url("https://cran.r-project.org/src/contrib/Archive/dplyr/dplyr_1.0.6.tar.gz")
install_url("http://cran.r-project.org/src/contrib/Archive/dplyr/dplyr_1.0.6.tar.gz")
source("~/GitHub/reu-2021/code/monte-carlo/perform-simulations.r", echo=TRUE)
source("~/GitHub/reu-2021/code/monte-carlo/perform-simulations.r", echo=TRUE)
source("~/GitHub/reu-2021/code/monte-carlo/perform-simulations.r", echo=TRUE)
>>>>>>> 31ca798af4d83283a2d378a6712ea85fc26a823b
