\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Ordinary Least Squares}{1}{}\protected@file@percent }
\citation{buehlmann2006boosting}
\citation{genuer2008random}
\citation{capitaine2021random}
\citation{james2013introduction}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Linear Regression with High Dimensionality Data}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Alternative Techniques with High Dimensionality Data}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Subset Selection}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Best Subset Selection}{2}{}\protected@file@percent }
\citation{lumley2020leaps}
\citation{james2017islr}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Number of fitted models depending on number of predictors (p)\relax }}{3}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:subset-combinations}{{1}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces $R^2$ and BIC when applying best subset selection\relax }}{3}{}\protected@file@percent }
\newlabel{fig:best-subset-selection}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Forward Stepwise Selection}{3}{}\protected@file@percent }
\citation{friedman2001elements}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces $R^2$ and BIC when applying forward stepwise selection\relax }}{4}{}\protected@file@percent }
\newlabel{fig:forward-stepwise-selection}{{2}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Backward Stepwise Selection}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Hybrid Stepwise Selection}{4}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces $R^2$ and BIC when applying backward stepwise selection\relax }}{5}{}\protected@file@percent }
\newlabel{fig:backward-stepwise-selection}{{3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Forward Stagewise Selection}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Penalized Regression}{5}{}\protected@file@percent }
\citation{tibshirani1996regression}
\citation{james2017islr}
\citation{james2013introduction}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Ridge Regression}{6}{}\protected@file@percent }
\newlabel{ridge_reg}{{8}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Lasso Regression}{6}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Error and constant curves for the lasso and ridge models when $p=2$.\relax }}{7}{}\protected@file@percent }
\newlabel{fig:ridge-lasso}{{4}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Elastic Net Regression}{7}{}\protected@file@percent }
\citation{zou2005regularization}
\citation{zou2006adaptive}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Instability of Lasso and Ridge Regression to Changes in Training Data\relax }}{8}{}\protected@file@percent }
\newlabel{fig:lasso-and-ridge-instability}{{5}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Adaptive Lasso Regression}{8}{}\protected@file@percent }
\citation{fan2001variable}
\citation{breheny2016lasso}
\citation{zhang2010nearly}
\citation{breheny2016lasso}
\citation{breheny2016lasso}
\newlabel{adap_lasso}{{14}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Smoothly Clipped Absolute Deviation Regression}{9}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Minimax Concave Penalty Regression}{9}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Penalty functions for LASSO, SCAD, and MCP, as well as their derivatives. These plots use $\lambda = 2$ and $a = 3$.\relax }}{10}{}\protected@file@percent }
\newlabel{fig:lasso-scad-mcp}{{6}{10}}
\newlabel{fig:penalty}{{6a}{10}}
\newlabel{sub@fig:penalty}{{a}{10}}
\newlabel{fig:derivative}{{6b}{10}}
\newlabel{sub@fig:derivative}{{b}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Solutions for LASSO, SCAD, and MCP for a single predictor when $\lambda =2$, and $a = 3$.\relax }}{10}{}\protected@file@percent }
\newlabel{fig:prediction}{{7}{10}}
\bibstyle{plain}
\bibdata{references}
\bibcite{lumley2020leaps}{1}
\bibcite{breheny2016lasso}{2}
\bibcite{buehlmann2006boosting}{3}
\bibcite{capitaine2021random}{4}
\bibcite{fan2001variable}{5}
\bibcite{friedman2001elements}{6}
\bibcite{genuer2008random}{7}
\bibcite{james2017islr}{8}
\bibcite{james2013introduction}{9}
\bibcite{tibshirani1996regression}{10}
\bibcite{zhang2010nearly}{11}
\bibcite{zou2006adaptive}{12}
\bibcite{zou2005regularization}{13}
\gdef \@abspage@last{11}
