\relax 
\citation{james2013introduction}
\citation{lumley2020leaps}
\citation{james2017islr}
\@writefile{toc}{\contentsline {section}{\numberline {1}Subset Selection}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Best Subset Selection}{1}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Number of fitted models depending on number of predictors (p)\relax }}{1}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:subset-combinations}{{1}{1}}
\newlabel{fig:best-subset-selection}{{\caption@xref {fig:best-subset-selection}{ on input line 73}}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces $R^2$ and BIC when applying best subset selection\relax }}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Forward Stepwise Selection}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Backward Stepwise Selection}{2}{}\protected@file@percent }
\citation{friedman2001elements}
\newlabel{fig:forward-stepwise-selection}{{\caption@xref {fig:forward-stepwise-selection}{ on input line 87}}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces $R^2$ and BIC when applying forward stepwise selection\relax }}{3}{}\protected@file@percent }
\newlabel{fig:backward-stepwise-selection}{{\caption@xref {fig:backward-stepwise-selection}{ on input line 101}}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces $R^2$ and BIC when applying backward stepwise selection\relax }}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.4}Hybrid Stepwise Selection}{3}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.5}Forward Stagewise Selection}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Penalized Regression}{4}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Ridge Regression}{4}{}\protected@file@percent }
\citation{tibshirani1996regression}
\citation{james2017islr}
\citation{james2013introduction}
\citation{zou2005regularization}
\citation{zou2006adaptive}
\newlabel{ridge_reg}{{3}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Lasso Regression}{5}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Elastic Net Regression}{5}{}\protected@file@percent }
\citation{fan2001variable}
\citation{zhang2010nearly}
\citation{breheny2016lasso}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Adaptive Lasso Regression}{6}{}\protected@file@percent }
\newlabel{adap_lasso}{{9}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Smoothly Clipped Absolute Deviation Regression}{6}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6}Minmax Concave Penalty Regression}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Penalty functions for LASSO, SCAD, and MCP, as well as their derivatives. These plots use $\lambda = 2$ and $a = 3$.\relax }}{7}{}\protected@file@percent }
\newlabel{fig:lasso-scad-mcp}{{4}{7}}
\newlabel{fig:penalty}{{4a}{7}}
\newlabel{sub@fig:penalty}{{a}{7}}
\newlabel{fig:derivative}{{4b}{7}}
\newlabel{sub@fig:derivative}{{b}{7}}
\bibstyle{plain}
\bibdata{references}
\bibcite{lumley2020leaps}{1}
\bibcite{breheny2016lasso}{2}
\bibcite{fan2001variable}{3}
\bibcite{friedman2001elements}{4}
\bibcite{james2017islr}{5}
\bibcite{james2013introduction}{6}
\bibcite{tibshirani1996regression}{7}
\bibcite{zhang2010nearly}{8}
\bibcite{zou2006adaptive}{9}
\bibcite{zou2005regularization}{10}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Solutions for LASSO, SCAD, and MCP for a single predictor when $\lambda =2$, and $a = 3$.\relax }}{8}{}\protected@file@percent }
\newlabel{fig:prediction}{{5}{8}}
\gdef \@abspage@last{8}
